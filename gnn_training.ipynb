{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db77a320-6617-4b0e-8525-bd15062b3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user4ferrum/gsv/VSharp/VSharp.ML.AIAgent/nvidia_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torch_geometric.utils import erdos_renyi_graph\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039153f5-9c4d-4e2d-96b1-6550dbe3fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = Path(\"./models\")\n",
    "\n",
    "if not MODELS_PATH.exists():\n",
    "    os.makedirs(MODELS_PATH)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383ab3e9-af4a-4207-8f29-009c863a7abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9cf612-840a-48bc-9701-92487482ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graphs = 200\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ''\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        l = []\n",
    "        for i in range(n_graphs):\n",
    "            l.append(\"data_\" + str(i) + \".pt\")\n",
    "        return l\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for g in range(n_graphs):                    \n",
    "            x = torch.rand([torch.randint(low=20, high=70, size=[1]), 1], dtype=torch.float32)\n",
    "            edge_index = erdos_renyi_graph(x.size()[0], 0.3)            \n",
    "            data = Data(x=x, edge_index=edge_index.contiguous())\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b793c2-5009-470b-a54e-79b69da2c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = RandomDataset(root=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82b96e9-aaf1-4e12-8abd-e58312aa533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConvModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64, num_layers=2, out_channels=1):\n",
    "        super(SAGEConvModel, self).__init__()\n",
    "        self.sage = GraphSAGE(dataset.num_features, hidden_channels, num_layers, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.sage(x, edge_index)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411e5a3a-b049-4524-b368-2b99ea926155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(batchX, randomFriend, randomEnemies, Q=1):\n",
    "    fst = -torch.log(torch.sigmoid(torch.sum(batchX * randomFriend, dim=1)))\n",
    "    snd = -Nenem * torch.mean(torch.log(torch.sigmoid(-torch.sum(randomEnemies * batchX,  dim=2))), dim=0)\n",
    "    return torch.mean(fst+snd)\n",
    "\n",
    "def get_random_repr(node, x, edge_dict):\n",
    "    variants = edge_dict.get(node, [])\n",
    "    if variants:\n",
    "        return x[np.random.choice(variants)]\n",
    "    return torch.zeros(out_channels)\n",
    "\n",
    "def get_dict_out_of_nodes(Nnodes, edge_index):\n",
    "    edge_dict = {i:[] for i in range(Nnodes)}\n",
    "    for edge in edge_index.reshape(-1,2).cpu().numpy():\n",
    "        edge_dict[edge[0]].append(edge[1])\n",
    "    return edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9f2e5b4-e016-4756-9ec6-34c6c3859f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "criterion = loss_fn\n",
    "\n",
    "epochs = 50\n",
    "n_models = 50\n",
    "out_channels = 10\n",
    "Nenem = 10\n",
    "n_features = 1\n",
    "num_layers = 3\n",
    "\n",
    "models_result = []\n",
    "\n",
    "def train():\n",
    "    for i in range(n_models):\n",
    "        torch.manual_seed(i)\n",
    "        model = SAGEConvModel(num_layers=num_layers, out_channels=out_channels)\n",
    "        model.to(DEVICE)\n",
    "        model.bfloat16()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = []\n",
    "            for g in dataset:\n",
    "                g.to(DEVICE)\n",
    "                model.train()\n",
    "                out = model(g.x.to(torch.bfloat16), g.edge_index)\n",
    "\n",
    "                idxperm = torch.randperm(out.size()[0])\n",
    "                # pidxs  = idxperm[batch*Nbatch:(batch+1)*Nbatch]\n",
    "                out = out[idxperm]\n",
    "                edge_dict = get_dict_out_of_nodes(out.size()[0], g.edge_index)\n",
    "                get_random_repr_p = partial(get_random_repr, x=out.cpu(), edge_dict=edge_dict)\n",
    "                randomFriend = torch.stack(list(map(get_random_repr_p, idxperm.numpy())), dim=0).to(DEVICE)\n",
    "                randomEnemies = out[np.random.choice(g.x.size()[0], Nenem)].reshape(Nenem, 1, out_channels).to(DEVICE)\n",
    "                \n",
    "                loss = criterion(out, randomFriend, randomEnemies)            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "    \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Model {i}: epoch: {epoch + 1:03d}, loss: {np.mean(train_loss)}')\n",
    "\n",
    "        models_result.append(model(dataset[0].x.to(torch.bfloat16).to(DEVICE), dataset[0].edge_index.to(DEVICE)))\n",
    "        for g in dataset[1:]:\n",
    "            g.to(DEVICE)\n",
    "            models_result[i] = torch.cat([models_result[i], model(g.x.to(torch.bfloat16), g.edge_index)])\n",
    "        torch.save(model.state_dict(), f'./models/{i+1}')\n",
    "\n",
    "\n",
    "def eval_stability():\n",
    "    disagr = 0\n",
    "    for i in range(n_models):\n",
    "        for j in range(i, n_models):   \n",
    "            disagr += torch.sum(torch.abs(models_result[i] - models_result[j])) / models_result[i].size()[0]\n",
    "    return disagr / (n_models * (n_models - 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f04d82d-3c97-478c-b3e6-03a8b4e5542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: epoch: 010, loss: 8.124897985458373\n",
      "Model 0: epoch: 020, loss: 8.124892420768738\n",
      "Model 0: epoch: 030, loss: 8.124884567260743\n",
      "Model 0: epoch: 040, loss: 8.124888019561768\n",
      "Model 0: epoch: 050, loss: 8.1248969745636\n",
      "Model 1: epoch: 010, loss: 8.124892659187317\n",
      "Model 1: epoch: 020, loss: 8.124895482063293\n",
      "Model 1: epoch: 030, loss: 8.125185613632203\n",
      "Model 1: epoch: 040, loss: 8.124885783195495\n",
      "Model 1: epoch: 050, loss: 8.1249036693573\n",
      "Model 2: epoch: 010, loss: 8.124896202087402\n",
      "Model 2: epoch: 020, loss: 8.124893164634704\n",
      "Model 2: epoch: 030, loss: 8.124888343811035\n",
      "Model 2: epoch: 040, loss: 8.124899797439575\n",
      "Model 2: epoch: 050, loss: 8.124900584220887\n",
      "Model 3: epoch: 010, loss: 8.124897508621215\n",
      "Model 3: epoch: 020, loss: 8.124896349906921\n",
      "Model 3: epoch: 030, loss: 8.12488651752472\n",
      "Model 3: epoch: 040, loss: 8.124895310401916\n",
      "Model 3: epoch: 050, loss: 8.12489914894104\n",
      "Model 4: epoch: 010, loss: 8.124896216392518\n",
      "Model 4: epoch: 020, loss: 8.124889855384827\n",
      "Model 4: epoch: 030, loss: 8.124896335601807\n",
      "Model 4: epoch: 040, loss: 8.12489535331726\n",
      "Model 4: epoch: 050, loss: 8.12490300655365\n",
      "Model 5: epoch: 010, loss: 8.12489435195923\n",
      "Model 5: epoch: 020, loss: 8.124890909194946\n",
      "Model 5: epoch: 030, loss: 8.124890522956848\n",
      "Model 5: epoch: 040, loss: 8.124891004562379\n",
      "Model 5: epoch: 050, loss: 8.12489402294159\n",
      "Model 6: epoch: 010, loss: 8.124898738861084\n",
      "Model 6: epoch: 020, loss: 8.124893655776978\n",
      "Model 6: epoch: 030, loss: 8.124895701408386\n",
      "Model 6: epoch: 040, loss: 8.124901475906372\n",
      "Model 6: epoch: 050, loss: 8.124901475906372\n",
      "Model 7: epoch: 010, loss: 8.124895086288452\n",
      "Model 7: epoch: 020, loss: 8.124887166023255\n",
      "Model 7: epoch: 030, loss: 8.124880962371826\n",
      "Model 7: epoch: 040, loss: 8.124883885383605\n",
      "Model 7: epoch: 050, loss: 8.124892492294311\n",
      "Model 8: epoch: 010, loss: 8.124896392822265\n",
      "Model 8: epoch: 020, loss: 8.124890322685241\n",
      "Model 8: epoch: 030, loss: 8.124895458221436\n",
      "Model 8: epoch: 040, loss: 8.124892020225525\n",
      "Model 8: epoch: 050, loss: 8.124889154434204\n",
      "Model 9: epoch: 010, loss: 8.12489598274231\n",
      "Model 9: epoch: 020, loss: 8.124891834259033\n",
      "Model 9: epoch: 030, loss: 8.124894170761108\n",
      "Model 9: epoch: 040, loss: 8.124896349906921\n",
      "Model 9: epoch: 050, loss: 8.124901475906372\n",
      "Model 10: epoch: 010, loss: 8.124894580841065\n",
      "Model 10: epoch: 020, loss: 8.124897298812867\n",
      "Model 10: epoch: 030, loss: 8.124889874458313\n",
      "Model 10: epoch: 040, loss: 8.124897618293762\n",
      "Model 10: epoch: 050, loss: 8.124901037216187\n",
      "Model 11: epoch: 010, loss: 8.12489534854889\n",
      "Model 11: epoch: 020, loss: 8.124892373085022\n",
      "Model 11: epoch: 030, loss: 8.124887218475342\n",
      "Model 11: epoch: 040, loss: 8.124888229370118\n",
      "Model 11: epoch: 050, loss: 8.124901475906372\n",
      "Model 12: epoch: 010, loss: 8.12489637374878\n",
      "Model 12: epoch: 020, loss: 8.12489646911621\n",
      "Model 12: epoch: 030, loss: 8.124890880584717\n",
      "Model 12: epoch: 040, loss: 8.124888682365418\n",
      "Model 12: epoch: 050, loss: 8.124901475906372\n",
      "Model 13: epoch: 010, loss: 8.124895572662354\n",
      "Model 13: epoch: 020, loss: 8.12489164352417\n",
      "Model 13: epoch: 030, loss: 8.124888744354248\n",
      "Model 13: epoch: 040, loss: 8.12489082813263\n",
      "Model 13: epoch: 050, loss: 8.124901475906372\n",
      "Model 14: epoch: 010, loss: 8.124890627861022\n",
      "Model 14: epoch: 020, loss: 8.124892077445985\n",
      "Model 14: epoch: 030, loss: 8.124895310401916\n",
      "Model 14: epoch: 040, loss: 8.124901599884033\n",
      "Model 14: epoch: 050, loss: 8.124901475906372\n",
      "Model 15: epoch: 010, loss: 8.124898114204406\n",
      "Model 15: epoch: 020, loss: 8.12489043712616\n",
      "Model 15: epoch: 030, loss: 8.12489221572876\n",
      "Model 15: epoch: 040, loss: 8.12488311290741\n",
      "Model 15: epoch: 050, loss: 8.124901475906372\n",
      "Model 16: epoch: 010, loss: 8.124897413253784\n",
      "Model 16: epoch: 020, loss: 8.124892196655274\n",
      "Model 16: epoch: 030, loss: 8.124889855384827\n",
      "Model 16: epoch: 040, loss: 8.124901475906372\n",
      "Model 16: epoch: 050, loss: 8.124901475906372\n",
      "Model 17: epoch: 010, loss: 8.12489743232727\n",
      "Model 17: epoch: 020, loss: 8.124888095855713\n",
      "Model 17: epoch: 030, loss: 8.124887251853943\n",
      "Model 17: epoch: 040, loss: 8.124890422821045\n",
      "Model 17: epoch: 050, loss: 8.124901475906372\n",
      "Model 18: epoch: 010, loss: 8.12489408493042\n",
      "Model 18: epoch: 020, loss: 8.124892959594726\n",
      "Model 18: epoch: 030, loss: 8.124893813133239\n",
      "Model 18: epoch: 040, loss: 8.12488422870636\n",
      "Model 18: epoch: 050, loss: 8.12489785194397\n",
      "Model 19: epoch: 010, loss: 8.124895868301392\n",
      "Model 19: epoch: 020, loss: 8.124890608787537\n",
      "Model 19: epoch: 030, loss: 8.124888162612915\n",
      "Model 19: epoch: 040, loss: 8.12489109992981\n",
      "Model 19: epoch: 050, loss: 8.124901475906372\n",
      "Model 20: epoch: 010, loss: 8.124896411895753\n",
      "Model 20: epoch: 020, loss: 8.124893679618836\n",
      "Model 20: epoch: 030, loss: 8.124893198013305\n",
      "Model 20: epoch: 040, loss: 8.124891848564149\n",
      "Model 20: epoch: 050, loss: 8.124896326065063\n",
      "Model 21: epoch: 010, loss: 8.124896106719971\n",
      "Model 21: epoch: 020, loss: 8.124896273612976\n",
      "Model 21: epoch: 030, loss: 8.1248898935318\n",
      "Model 21: epoch: 040, loss: 8.12489508152008\n",
      "Model 21: epoch: 050, loss: 8.124892253875732\n",
      "Model 22: epoch: 010, loss: 8.1248992395401\n",
      "Model 22: epoch: 020, loss: 8.12489752292633\n",
      "Model 22: epoch: 030, loss: 8.124892749786376\n",
      "Model 22: epoch: 040, loss: 8.124887986183166\n",
      "Model 22: epoch: 050, loss: 8.124892449378967\n",
      "Model 23: epoch: 010, loss: 8.124895777702331\n",
      "Model 23: epoch: 020, loss: 8.124898233413695\n",
      "Model 23: epoch: 030, loss: 8.124892387390137\n",
      "Model 23: epoch: 040, loss: 8.12488513469696\n",
      "Model 23: epoch: 050, loss: 8.124889211654663\n",
      "Model 24: epoch: 010, loss: 8.124895906448364\n",
      "Model 24: epoch: 020, loss: 8.124889469146728\n",
      "Model 24: epoch: 030, loss: 8.124885354042053\n",
      "Model 24: epoch: 040, loss: 8.124884238243103\n",
      "Model 24: epoch: 050, loss: 8.12488278388977\n",
      "Model 25: epoch: 010, loss: 8.12489661693573\n",
      "Model 25: epoch: 020, loss: 8.124897165298462\n",
      "Model 25: epoch: 030, loss: 8.124889135360718\n",
      "Model 25: epoch: 040, loss: 8.124890737533569\n",
      "Model 25: epoch: 050, loss: 8.124902334213257\n",
      "Model 26: epoch: 010, loss: 8.124899063110352\n",
      "Model 26: epoch: 020, loss: 8.12489535331726\n",
      "Model 26: epoch: 030, loss: 8.124890933036804\n",
      "Model 26: epoch: 040, loss: 8.124888978004456\n",
      "Model 26: epoch: 050, loss: 8.124891600608827\n",
      "Model 27: epoch: 010, loss: 8.12489568710327\n",
      "Model 27: epoch: 020, loss: 8.124896874427796\n",
      "Model 27: epoch: 030, loss: 8.124892492294311\n",
      "Model 27: epoch: 040, loss: 8.124877200126647\n",
      "Model 27: epoch: 050, loss: 8.124897575378418\n",
      "Model 28: epoch: 010, loss: 8.124896368980409\n",
      "Model 28: epoch: 020, loss: 8.124894423484802\n",
      "Model 28: epoch: 030, loss: 8.124895005226135\n",
      "Model 28: epoch: 040, loss: 8.124894590377808\n",
      "Model 28: epoch: 050, loss: 8.124903230667114\n",
      "Model 29: epoch: 010, loss: 8.124900317192077\n",
      "Model 29: epoch: 020, loss: 8.124892320632934\n",
      "Model 29: epoch: 030, loss: 8.124891934394837\n",
      "Model 29: epoch: 040, loss: 8.124893918037415\n",
      "Model 29: epoch: 050, loss: 8.12489483833313\n",
      "Model 30: epoch: 010, loss: 8.124895596504212\n",
      "Model 30: epoch: 020, loss: 8.124886031150817\n",
      "Model 30: epoch: 030, loss: 8.12489300251007\n",
      "Model 30: epoch: 040, loss: 8.124889354705811\n",
      "Model 30: epoch: 050, loss: 8.12489456653595\n",
      "Model 31: epoch: 010, loss: 8.124897336959839\n",
      "Model 31: epoch: 020, loss: 8.124887166023255\n",
      "Model 31: epoch: 030, loss: 8.124898028373718\n",
      "Model 31: epoch: 040, loss: 8.124901480674744\n",
      "Model 31: epoch: 050, loss: 8.124901475906372\n",
      "Model 32: epoch: 010, loss: 8.12489764213562\n",
      "Model 32: epoch: 020, loss: 8.124898386001586\n",
      "Model 32: epoch: 030, loss: 8.12489785671234\n",
      "Model 32: epoch: 040, loss: 8.124894919395446\n",
      "Model 32: epoch: 050, loss: 8.124901475906372\n",
      "Model 33: epoch: 010, loss: 8.124897532463073\n",
      "Model 33: epoch: 020, loss: 8.124889216423036\n",
      "Model 33: epoch: 030, loss: 8.124886770248413\n",
      "Model 33: epoch: 040, loss: 8.124883985519409\n",
      "Model 33: epoch: 050, loss: 8.1249036693573\n",
      "Model 34: epoch: 010, loss: 8.124896993637085\n",
      "Model 34: epoch: 020, loss: 8.124891228675843\n",
      "Model 34: epoch: 030, loss: 8.124887747764587\n",
      "Model 34: epoch: 040, loss: 8.124888801574707\n",
      "Model 34: epoch: 050, loss: 8.124902448654176\n",
      "Model 35: epoch: 010, loss: 8.124895439147949\n",
      "Model 35: epoch: 020, loss: 8.124892716407777\n",
      "Model 35: epoch: 030, loss: 8.124883451461791\n",
      "Model 35: epoch: 040, loss: 8.124896621704101\n",
      "Model 35: epoch: 050, loss: 8.124894242286683\n",
      "Model 36: epoch: 010, loss: 8.124896359443664\n",
      "Model 36: epoch: 020, loss: 8.124889059066772\n",
      "Model 36: epoch: 030, loss: 8.124901013374329\n",
      "Model 36: epoch: 040, loss: 8.12488929271698\n",
      "Model 36: epoch: 050, loss: 8.124901423454284\n",
      "Model 37: epoch: 010, loss: 8.124896006584168\n",
      "Model 37: epoch: 020, loss: 8.124890413284302\n",
      "Model 37: epoch: 030, loss: 8.12489640712738\n",
      "Model 37: epoch: 040, loss: 8.124877576828004\n",
      "Model 37: epoch: 050, loss: 8.124901475906372\n",
      "Model 38: epoch: 010, loss: 8.124896454811097\n",
      "Model 38: epoch: 020, loss: 8.12489628791809\n",
      "Model 38: epoch: 030, loss: 8.124889979362488\n",
      "Model 38: epoch: 040, loss: 8.124885349273681\n",
      "Model 38: epoch: 050, loss: 8.124885988235473\n",
      "Model 39: epoch: 010, loss: 8.124898400306702\n",
      "Model 39: epoch: 020, loss: 8.124892582893372\n",
      "Model 39: epoch: 030, loss: 8.124888772964477\n",
      "Model 39: epoch: 040, loss: 8.124892168045044\n",
      "Model 39: epoch: 050, loss: 8.124894824028015\n",
      "Model 40: epoch: 010, loss: 8.124896640777587\n",
      "Model 40: epoch: 020, loss: 8.12489534854889\n",
      "Model 40: epoch: 030, loss: 8.124895958900451\n",
      "Model 40: epoch: 040, loss: 8.124892764091491\n",
      "Model 40: epoch: 050, loss: 8.124896636009217\n",
      "Model 41: epoch: 010, loss: 8.124896221160888\n",
      "Model 41: epoch: 020, loss: 8.124891576766968\n",
      "Model 41: epoch: 030, loss: 8.124898409843444\n",
      "Model 41: epoch: 040, loss: 8.124901475906372\n",
      "Model 41: epoch: 050, loss: 8.124901475906372\n",
      "Model 42: epoch: 010, loss: 8.124897670745849\n",
      "Model 42: epoch: 020, loss: 8.124892148971558\n",
      "Model 42: epoch: 030, loss: 8.124894552230835\n",
      "Model 42: epoch: 040, loss: 8.124887208938599\n",
      "Model 42: epoch: 050, loss: 8.124892754554748\n",
      "Model 43: epoch: 010, loss: 8.124896817207336\n",
      "Model 43: epoch: 020, loss: 8.124891571998596\n",
      "Model 43: epoch: 030, loss: 8.12488748550415\n",
      "Model 43: epoch: 040, loss: 8.124899892807006\n",
      "Model 43: epoch: 050, loss: 8.124901475906372\n",
      "Model 44: epoch: 010, loss: 8.124892988204955\n",
      "Model 44: epoch: 020, loss: 8.124888529777527\n",
      "Model 44: epoch: 030, loss: 8.124891772270203\n",
      "Model 44: epoch: 040, loss: 8.12490128993988\n",
      "Model 44: epoch: 050, loss: 8.124900403022766\n",
      "Model 45: epoch: 010, loss: 8.12489402294159\n",
      "Model 45: epoch: 020, loss: 8.124889450073242\n",
      "Model 45: epoch: 030, loss: 8.124895749092103\n",
      "Model 45: epoch: 040, loss: 8.12490098953247\n",
      "Model 45: epoch: 050, loss: 8.12490098953247\n",
      "Model 46: epoch: 010, loss: 8.124900155067444\n",
      "Model 46: epoch: 020, loss: 8.124894785881043\n",
      "Model 46: epoch: 030, loss: 8.12489200115204\n",
      "Model 46: epoch: 040, loss: 8.124888186454774\n",
      "Model 46: epoch: 050, loss: 8.124901475906372\n",
      "Model 47: epoch: 010, loss: 8.124898400306702\n",
      "Model 47: epoch: 020, loss: 8.124890241622925\n",
      "Model 47: epoch: 030, loss: 8.12488929271698\n",
      "Model 47: epoch: 040, loss: 8.124895749092103\n",
      "Model 47: epoch: 050, loss: 8.124901475906372\n",
      "Model 48: epoch: 010, loss: 8.12489456653595\n",
      "Model 48: epoch: 020, loss: 8.124886922836303\n",
      "Model 48: epoch: 030, loss: 8.124885029792786\n",
      "Model 48: epoch: 040, loss: 8.124898023605347\n",
      "Model 48: epoch: 050, loss: 8.124901475906372\n",
      "Model 49: epoch: 010, loss: 8.124895653724671\n",
      "Model 49: epoch: 020, loss: 8.12489628791809\n",
      "Model 49: epoch: 030, loss: 8.124897885322572\n",
      "Model 49: epoch: 040, loss: 8.124901475906372\n",
      "Model 49: epoch: 050, loss: 8.124901475906372\n",
      "Stability: tensor(0.0513, device='cuda:0', dtype=torch.bfloat16, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "d = eval_stability()\n",
    "print(\"Stability:\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23940857-3cb1-4bb0-a403-35180e108087",
   "metadata": {},
   "source": [
    "2 layers \\\n",
    "float32 0.2288476824760437 \\\n",
    "float64 0.21959084776105314 \\\n",
    "bfloat16 0.10107421875 \n",
    "\n",
    "1 layer \\\n",
    "bfloat16 0.201171875 \\\n",
    "float32 0.7191293835639954 \\\n",
    "float64 0.6989535146025564 \n",
    "\n",
    "3 layers \\\n",
    "float64 0.2054728962831928 \\\n",
    "float32 0.2074834555387497\\\n",
    "bfloat16 0.05126953125"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
