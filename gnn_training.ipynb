{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db77a320-6617-4b0e-8525-bd15062b3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chivi\\gnnstability\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torch_geometric.utils import erdos_renyi_graph\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "from torch_geometric.data import Data, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039153f5-9c4d-4e2d-96b1-6550dbe3fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = Path(\"./models\")\n",
    "\n",
    "if not MODELS_PATH.exists():\n",
    "    os.makedirs(MODELS_PATH)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "383ab3e9-af4a-4207-8f29-009c863a7abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9cf612-840a-48bc-9701-92487482ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graphs = 200\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ''\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        l = []\n",
    "        for i in range(n_graphs):\n",
    "            l.append(\"data_\" + str(i) + \".pt\")\n",
    "        return l\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for g in range(n_graphs):                    \n",
    "            x = torch.rand([torch.randint(low=20, high=70, size=[1]), 1], dtype=torch.float32)\n",
    "            edge_index = erdos_renyi_graph(x.size()[0], 0.3)            \n",
    "            data = Data(x=x, edge_index=edge_index.contiguous())\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b793c2-5009-470b-a54e-79b69da2c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RandomDataset(root=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82b96e9-aaf1-4e12-8abd-e58312aa533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConvModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64, num_layers=2, out_channels=1):\n",
    "        super(SAGEConvModel, self).__init__()\n",
    "        self.sage = GraphSAGE(dataset.num_features, hidden_channels, num_layers, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.sage(x, edge_index)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411e5a3a-b049-4524-b368-2b99ea926155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(batchX, randomFriend, randomEnemies, Q=1):\n",
    "    fst = -torch.log(torch.sigmoid(torch.sum(batchX * randomFriend, dim=1)))\n",
    "    snd = -Nenem * torch.mean(torch.log(torch.sigmoid(-torch.sum(randomEnemies * batchX,  dim=2))), dim=0)\n",
    "    return torch.mean(fst+snd)\n",
    "\n",
    "def get_random_repr(node, x, edge_dict):\n",
    "    variants = edge_dict.get(node, [])\n",
    "    if variants:\n",
    "        return x[np.random.choice(variants)]\n",
    "    return torch.zeros(out_channels)\n",
    "\n",
    "def get_dict_out_of_nodes(Nnodes, edge_index):\n",
    "    edge_dict = {i:[] for i in range(Nnodes)}\n",
    "    for edge in edge_index.reshape(-1,2).cpu().numpy():\n",
    "        edge_dict[edge[0]].append(edge[1])\n",
    "    return edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f2e5b4-e016-4756-9ec6-34c6c3859f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "from functools import partial\n",
    "criterion = loss_fn\n",
    "\n",
    "epochs = 50\n",
    "n_models = 50\n",
    "out_channels = 10\n",
    "Nenem = 10\n",
    "n_features = 1\n",
    "num_layers = 3\n",
    "\n",
    "models_result = []\n",
    "\n",
    "def train():\n",
    "    for i in range(n_models):\n",
    "        torch.manual_seed(i)\n",
    "        model = SAGEConvModel(num_layers=num_layers, out_channels=out_channels)\n",
    "        model.to(DEVICE)\n",
    "        # model.double()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = []\n",
    "            for g in dataset:\n",
    "                g.to(DEVICE)\n",
    "                model.train()\n",
    "                out = model(g.x.to(torch.float32), g.edge_index)\n",
    "\n",
    "                idxperm = torch.randperm(out.size()[0])\n",
    "                # pidxs  = idxperm[batch*Nbatch:(batch+1)*Nbatch]\n",
    "                out = out[idxperm]\n",
    "                edge_dict = get_dict_out_of_nodes(out.size()[0], g.edge_index)\n",
    "                get_random_repr_p = partial(get_random_repr, x=out, edge_dict=edge_dict)\n",
    "                randomFriend = torch.stack(list(map(get_random_repr_p, idxperm.numpy())), dim=0).to(DEVICE)\n",
    "                randomEnemies = out[np.random.choice(g.x.size()[0], Nenem)].reshape(Nenem, 1, out_channels).to(DEVICE)\n",
    "                \n",
    "                loss = criterion(out, randomFriend, randomEnemies)            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss.append(loss.item())\n",
    "    \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Model {i}: epoch: {epoch + 1:03d}, loss: {np.mean(train_loss)}')\n",
    "\n",
    "        models_result.append(model(dataset[0].x.to(torch.float32), dataset[0].edge_index))\n",
    "        for g in dataset[1:]:\n",
    "            models_result[i] = torch.cat([models_result[i], model(g.x.to(torch.float32), g.edge_index)])\n",
    "        torch.save(model.state_dict(), f'./models/{i+1}')\n",
    "\n",
    "\n",
    "def eval_stability():\n",
    "    disagr = 0\n",
    "    for i in range(n_models):\n",
    "        for j in range(i, n_models):   \n",
    "            disagr += torch.sum(torch.abs(models_result[i] - models_result[j])) / models_result[i].size()[0]\n",
    "    return disagr / (n_models * (n_models + 1) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f04d82d-3c97-478c-b3e6-03a8b4e5542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: epoch: 010, loss: 8.101938920021057\n",
      "Model 0: epoch: 020, loss: 8.098837537765503\n",
      "Model 0: epoch: 030, loss: 8.109405617713929\n",
      "Model 0: epoch: 040, loss: 8.106246495246888\n",
      "Model 0: epoch: 050, loss: 8.093907990455627\n",
      "Model 1: epoch: 010, loss: 8.09745801448822\n",
      "Model 1: epoch: 020, loss: 8.09821361064911\n",
      "Model 1: epoch: 030, loss: 8.102283091545106\n",
      "Model 1: epoch: 040, loss: 8.108295373916626\n",
      "Model 1: epoch: 050, loss: 8.113085570335388\n",
      "Model 2: epoch: 010, loss: 8.094871244430543\n",
      "Model 2: epoch: 020, loss: 8.096293849945068\n",
      "Model 2: epoch: 030, loss: 8.101992859840394\n",
      "Model 2: epoch: 040, loss: 8.10881190776825\n",
      "Model 2: epoch: 050, loss: 8.106374373435974\n",
      "Model 3: epoch: 010, loss: 8.09601707458496\n",
      "Model 3: epoch: 020, loss: 8.100526375770569\n",
      "Model 3: epoch: 030, loss: 8.102142906188964\n",
      "Model 3: epoch: 040, loss: 8.105073771476746\n",
      "Model 3: epoch: 050, loss: 8.11139690876007\n",
      "Model 4: epoch: 010, loss: 8.095027899742126\n",
      "Model 4: epoch: 020, loss: 8.098659772872924\n",
      "Model 4: epoch: 030, loss: 8.099243664741516\n",
      "Model 4: epoch: 040, loss: 8.098142557144165\n",
      "Model 4: epoch: 050, loss: 8.115728974342346\n",
      "Model 5: epoch: 010, loss: 8.098733763694764\n",
      "Model 5: epoch: 020, loss: 8.103635540008545\n",
      "Model 5: epoch: 030, loss: 8.09907133579254\n",
      "Model 5: epoch: 040, loss: 8.104008507728576\n",
      "Model 5: epoch: 050, loss: 8.100635662078858\n",
      "Model 6: epoch: 010, loss: 8.09918694972992\n",
      "Model 6: epoch: 020, loss: 8.098268113136292\n",
      "Model 6: epoch: 030, loss: 8.10595543384552\n",
      "Model 6: epoch: 040, loss: 8.105605273246764\n",
      "Model 6: epoch: 050, loss: 8.10208909034729\n",
      "Model 7: epoch: 010, loss: 8.096232137680055\n",
      "Model 7: epoch: 020, loss: 8.097623715400696\n",
      "Model 7: epoch: 030, loss: 8.108835396766663\n",
      "Model 7: epoch: 040, loss: 8.10627398967743\n",
      "Model 7: epoch: 050, loss: 8.11026137828827\n",
      "Model 8: epoch: 010, loss: 8.096457014083862\n",
      "Model 8: epoch: 020, loss: 8.096509594917297\n",
      "Model 8: epoch: 030, loss: 8.094892106056214\n",
      "Model 8: epoch: 040, loss: 8.102077741622924\n",
      "Model 8: epoch: 050, loss: 8.10795868396759\n",
      "Model 9: epoch: 010, loss: 8.098089203834533\n",
      "Model 9: epoch: 020, loss: 8.098064103126525\n",
      "Model 9: epoch: 030, loss: 8.10019263267517\n",
      "Model 9: epoch: 040, loss: 8.103844947814942\n",
      "Model 9: epoch: 050, loss: 8.105189461708068\n",
      "Model 10: epoch: 010, loss: 8.095682520866394\n",
      "Model 10: epoch: 020, loss: 8.095915408134461\n",
      "Model 10: epoch: 030, loss: 8.106693544387817\n",
      "Model 10: epoch: 040, loss: 8.113306107521057\n",
      "Model 10: epoch: 050, loss: 8.103907213211059\n",
      "Model 11: epoch: 010, loss: 8.098549270629883\n",
      "Model 11: epoch: 020, loss: 8.102161202430725\n",
      "Model 11: epoch: 030, loss: 8.103711948394775\n",
      "Model 11: epoch: 040, loss: 8.104213852882385\n",
      "Model 11: epoch: 050, loss: 8.1027969789505\n",
      "Model 12: epoch: 010, loss: 8.09861828804016\n",
      "Model 12: epoch: 020, loss: 8.098325119018554\n",
      "Model 12: epoch: 030, loss: 8.105935845375061\n",
      "Model 12: epoch: 040, loss: 8.116195163726807\n",
      "Model 12: epoch: 050, loss: 8.098982768058777\n",
      "Model 13: epoch: 010, loss: 8.096489715576173\n",
      "Model 13: epoch: 020, loss: 8.097669744491578\n",
      "Model 13: epoch: 030, loss: 8.102980508804322\n",
      "Model 13: epoch: 040, loss: 8.109169578552246\n",
      "Model 13: epoch: 050, loss: 8.107044258117675\n",
      "Model 14: epoch: 010, loss: 8.097479104995728\n",
      "Model 14: epoch: 020, loss: 8.103044476509094\n",
      "Model 14: epoch: 030, loss: 8.099730877876281\n",
      "Model 14: epoch: 040, loss: 8.102982630729676\n",
      "Model 14: epoch: 050, loss: 8.098972706794738\n",
      "Model 15: epoch: 010, loss: 8.098990969657898\n",
      "Model 15: epoch: 020, loss: 8.105362329483032\n",
      "Model 15: epoch: 030, loss: 8.110122299194336\n",
      "Model 15: epoch: 040, loss: 8.103825635910034\n",
      "Model 15: epoch: 050, loss: 8.114565858840942\n",
      "Model 16: epoch: 010, loss: 8.096867966651917\n",
      "Model 16: epoch: 020, loss: 8.101563229560853\n",
      "Model 16: epoch: 030, loss: 8.102401847839355\n",
      "Model 16: epoch: 040, loss: 8.108766393661499\n",
      "Model 16: epoch: 050, loss: 8.113221373558044\n",
      "Model 17: epoch: 010, loss: 8.095553851127624\n",
      "Model 17: epoch: 020, loss: 8.095038294792175\n",
      "Model 17: epoch: 030, loss: 8.1013569688797\n",
      "Model 17: epoch: 040, loss: 8.104766969680787\n",
      "Model 17: epoch: 050, loss: 8.100572996139526\n",
      "Model 18: epoch: 010, loss: 8.097142062187196\n",
      "Model 18: epoch: 020, loss: 8.102799677848816\n",
      "Model 18: epoch: 030, loss: 8.107179408073426\n",
      "Model 18: epoch: 040, loss: 8.105135769844056\n",
      "Model 18: epoch: 050, loss: 8.099609875679016\n",
      "Model 19: epoch: 010, loss: 8.096899075508118\n",
      "Model 19: epoch: 020, loss: 8.10484338760376\n",
      "Model 19: epoch: 030, loss: 8.102420425415039\n",
      "Model 19: epoch: 040, loss: 8.10365773677826\n",
      "Model 19: epoch: 050, loss: 8.108007144927978\n",
      "Model 20: epoch: 010, loss: 8.09635281085968\n",
      "Model 20: epoch: 020, loss: 8.098279252052308\n",
      "Model 20: epoch: 030, loss: 8.101361765861512\n",
      "Model 20: epoch: 040, loss: 8.106785202026368\n",
      "Model 20: epoch: 050, loss: 8.098819041252137\n",
      "Model 21: epoch: 010, loss: 8.097175521850586\n",
      "Model 21: epoch: 020, loss: 8.100522694587708\n",
      "Model 21: epoch: 030, loss: 8.10788833618164\n",
      "Model 21: epoch: 040, loss: 8.107155680656433\n",
      "Model 21: epoch: 050, loss: 8.097187552452088\n",
      "Model 22: epoch: 010, loss: 8.094659795761109\n",
      "Model 22: epoch: 020, loss: 8.10320342540741\n",
      "Model 22: epoch: 030, loss: 8.103340601921081\n",
      "Model 22: epoch: 040, loss: 8.099639720916748\n",
      "Model 22: epoch: 050, loss: 8.10633107662201\n",
      "Model 23: epoch: 010, loss: 8.099239730834961\n",
      "Model 23: epoch: 020, loss: 8.10491708755493\n",
      "Model 23: epoch: 030, loss: 8.100701417922973\n",
      "Model 23: epoch: 040, loss: 8.098976140022279\n",
      "Model 23: epoch: 050, loss: 8.109570326805114\n",
      "Model 24: epoch: 010, loss: 8.096052584648133\n",
      "Model 24: epoch: 020, loss: 8.09932457447052\n",
      "Model 24: epoch: 030, loss: 8.099523968696595\n",
      "Model 24: epoch: 040, loss: 8.101120715141297\n",
      "Model 24: epoch: 050, loss: 8.105255756378174\n",
      "Model 25: epoch: 010, loss: 8.101616435050964\n",
      "Model 25: epoch: 020, loss: 8.101252307891846\n",
      "Model 25: epoch: 030, loss: 8.109274034500123\n",
      "Model 25: epoch: 040, loss: 8.104401183128356\n",
      "Model 25: epoch: 050, loss: 8.112805156707763\n",
      "Model 26: epoch: 010, loss: 8.094002571105957\n",
      "Model 26: epoch: 020, loss: 8.100561957359314\n",
      "Model 26: epoch: 030, loss: 8.107995462417602\n",
      "Model 26: epoch: 040, loss: 8.107743587493896\n",
      "Model 26: epoch: 050, loss: 8.106752796173096\n",
      "Model 27: epoch: 010, loss: 8.096423478126527\n",
      "Model 27: epoch: 020, loss: 8.100604720115662\n",
      "Model 27: epoch: 030, loss: 8.097668709754943\n",
      "Model 27: epoch: 040, loss: 8.096861882209778\n",
      "Model 27: epoch: 050, loss: 8.110852127075196\n",
      "Model 28: epoch: 010, loss: 8.097528204917907\n",
      "Model 28: epoch: 020, loss: 8.098027925491333\n",
      "Model 28: epoch: 030, loss: 8.101163663864135\n",
      "Model 28: epoch: 040, loss: 8.099997634887695\n",
      "Model 28: epoch: 050, loss: 8.10925537109375\n",
      "Model 29: epoch: 010, loss: 8.095907950401307\n",
      "Model 29: epoch: 020, loss: 8.101334886550903\n",
      "Model 29: epoch: 030, loss: 8.104814872741699\n",
      "Model 29: epoch: 040, loss: 8.108330178260804\n",
      "Model 29: epoch: 050, loss: 8.106095323562622\n",
      "Model 30: epoch: 010, loss: 8.096117157936096\n",
      "Model 30: epoch: 020, loss: 8.104910888671874\n",
      "Model 30: epoch: 030, loss: 8.100645785331727\n",
      "Model 30: epoch: 040, loss: 8.103108649253846\n",
      "Model 30: epoch: 050, loss: 8.102771940231323\n",
      "Model 31: epoch: 010, loss: 8.099452347755433\n",
      "Model 31: epoch: 020, loss: 8.100833654403687\n",
      "Model 31: epoch: 030, loss: 8.112181391716003\n",
      "Model 31: epoch: 040, loss: 8.113134450912476\n",
      "Model 31: epoch: 050, loss: 8.10465006351471\n",
      "Model 32: epoch: 010, loss: 8.098888440132141\n",
      "Model 32: epoch: 020, loss: 8.103231101036071\n",
      "Model 32: epoch: 030, loss: 8.108028321266174\n",
      "Model 32: epoch: 040, loss: 8.099823670387268\n",
      "Model 32: epoch: 050, loss: 8.11288034915924\n",
      "Model 33: epoch: 010, loss: 8.09765715122223\n",
      "Model 33: epoch: 020, loss: 8.10920964717865\n",
      "Model 33: epoch: 030, loss: 8.102288699150085\n",
      "Model 33: epoch: 040, loss: 8.098725547790528\n",
      "Model 33: epoch: 050, loss: 8.111114211082459\n",
      "Model 34: epoch: 010, loss: 8.09519639968872\n",
      "Model 34: epoch: 020, loss: 8.103913826942444\n",
      "Model 34: epoch: 030, loss: 8.107345561981202\n",
      "Model 34: epoch: 040, loss: 8.10853256702423\n",
      "Model 34: epoch: 050, loss: 8.115206351280213\n",
      "Model 35: epoch: 010, loss: 8.105258145332336\n",
      "Model 35: epoch: 020, loss: 8.09463056564331\n",
      "Model 35: epoch: 030, loss: 8.103075108528138\n",
      "Model 35: epoch: 040, loss: 8.101920657157898\n",
      "Model 35: epoch: 050, loss: 8.113864359855652\n",
      "Model 36: epoch: 010, loss: 8.09712836265564\n",
      "Model 36: epoch: 020, loss: 8.09988196849823\n",
      "Model 36: epoch: 030, loss: 8.106928534507752\n",
      "Model 36: epoch: 040, loss: 8.098330855369568\n",
      "Model 36: epoch: 050, loss: 8.11110981464386\n",
      "Model 37: epoch: 010, loss: 8.09950686454773\n",
      "Model 37: epoch: 020, loss: 8.109025712013244\n",
      "Model 37: epoch: 030, loss: 8.10345090866089\n",
      "Model 37: epoch: 040, loss: 8.101818900108338\n",
      "Model 37: epoch: 050, loss: 8.103544754981995\n",
      "Model 38: epoch: 010, loss: 8.092559523582459\n",
      "Model 38: epoch: 020, loss: 8.097860279083251\n",
      "Model 38: epoch: 030, loss: 8.100373268127441\n",
      "Model 38: epoch: 040, loss: 8.108312754631042\n",
      "Model 38: epoch: 050, loss: 8.10010708808899\n",
      "Model 39: epoch: 010, loss: 8.095337257385253\n",
      "Model 39: epoch: 020, loss: 8.101566395759583\n",
      "Model 39: epoch: 030, loss: 8.106575016975404\n",
      "Model 39: epoch: 040, loss: 8.113724908828736\n",
      "Model 39: epoch: 050, loss: 8.111544613838197\n",
      "Model 40: epoch: 010, loss: 8.095697345733642\n",
      "Model 40: epoch: 020, loss: 8.102091588973998\n",
      "Model 40: epoch: 030, loss: 8.108552346229553\n",
      "Model 40: epoch: 040, loss: 8.098248224258423\n",
      "Model 40: epoch: 050, loss: 8.105449595451354\n",
      "Model 41: epoch: 010, loss: 8.095540227890014\n",
      "Model 41: epoch: 020, loss: 8.101125078201294\n",
      "Model 41: epoch: 030, loss: 8.1035777759552\n",
      "Model 41: epoch: 040, loss: 8.103172163963318\n",
      "Model 41: epoch: 050, loss: 8.103051080703736\n",
      "Model 42: epoch: 010, loss: 8.098708481788636\n",
      "Model 42: epoch: 020, loss: 8.100597777366637\n",
      "Model 42: epoch: 030, loss: 8.102667570114136\n",
      "Model 42: epoch: 040, loss: 8.101603050231933\n",
      "Model 42: epoch: 050, loss: 8.102933926582336\n",
      "Model 43: epoch: 010, loss: 8.09703037261963\n",
      "Model 43: epoch: 020, loss: 8.10498884677887\n",
      "Model 43: epoch: 030, loss: 8.099349913597107\n",
      "Model 43: epoch: 040, loss: 8.105227179527283\n",
      "Model 43: epoch: 050, loss: 8.116689343452453\n",
      "Model 44: epoch: 010, loss: 8.094627895355224\n",
      "Model 44: epoch: 020, loss: 8.104366335868836\n",
      "Model 44: epoch: 030, loss: 8.105784912109375\n",
      "Model 44: epoch: 040, loss: 8.094532046318054\n",
      "Model 44: epoch: 050, loss: 8.107857089042664\n",
      "Model 45: epoch: 010, loss: 8.09512550830841\n",
      "Model 45: epoch: 020, loss: 8.100218291282653\n",
      "Model 45: epoch: 030, loss: 8.110879788398742\n",
      "Model 45: epoch: 040, loss: 8.110718669891357\n",
      "Model 45: epoch: 050, loss: 8.109077062606811\n",
      "Model 46: epoch: 010, loss: 8.096734228134155\n",
      "Model 46: epoch: 020, loss: 8.099452781677247\n",
      "Model 46: epoch: 030, loss: 8.09970012664795\n",
      "Model 46: epoch: 040, loss: 8.103499703407287\n",
      "Model 46: epoch: 050, loss: 8.101709547042846\n",
      "Model 47: epoch: 010, loss: 8.097569332122802\n",
      "Model 47: epoch: 020, loss: 8.101384768486023\n",
      "Model 47: epoch: 030, loss: 8.106567506790162\n",
      "Model 47: epoch: 040, loss: 8.11000871181488\n",
      "Model 47: epoch: 050, loss: 8.109304084777833\n",
      "Model 48: epoch: 010, loss: 8.09566683292389\n",
      "Model 48: epoch: 020, loss: 8.101077160835267\n",
      "Model 48: epoch: 030, loss: 8.100467519760132\n",
      "Model 48: epoch: 040, loss: 8.098577089309693\n",
      "Model 48: epoch: 050, loss: 8.109604063034057\n",
      "Model 49: epoch: 010, loss: 8.096257643699646\n",
      "Model 49: epoch: 020, loss: 8.10128870010376\n",
      "Model 49: epoch: 030, loss: 8.103805141448975\n",
      "Model 49: epoch: 040, loss: 8.110293369293213\n",
      "Model 49: epoch: 050, loss: 8.109139995574951\n",
      "Stability: tensor(0.2181, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "d = eval_stability()\n",
    "print(\"Stability:\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e7e22287-e2a9-4f40-9ecd-3f5ab099c143",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SAGEConvModel' object has no attribute 'float16'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(param\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\users\\chivi\\gnnstability\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SAGEConvModel' object has no attribute 'float16'"
     ]
    }
   ],
   "source": [
    "model.float16()\n",
    "for param in model.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "afd26a9c-acec-4916-8334-090ffc92d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2209, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_stability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82844558-61c1-448b-8630-85f8175ead64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "model = SAGEConvModel(num_layers=num_layers, out_channels=out_channels)\n",
    "for param in model.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3f190-4851-4544-a385-9b017b2f0341",
   "metadata": {},
   "source": [
    "2 layers\n",
    "float32 0.2209\n",
    "float64 0.2333\n",
    "bfloat16 0.1035\n",
    "\n",
    "1 layer\n",
    "bfloat16 0.2041\n",
    "float64 0.7173\n",
    "float32 0.7346\n",
    "\n",
    "3 layers\n",
    "float32 0.2181"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
